{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_SOLUTION.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEa8O_OU8RO_"
      },
      "source": [
        "# Sentiment Analysis \n",
        "\n",
        "La sentiment Analysis est le fait de regarder ce que vos clients pensent de votre produit. Dans ce tutoriel, nous allons essayer de comprendre ce que les gens pensent du parc d'attraction disneyland. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlZE3Ntm8gv4"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpRfWDCp9vlf"
      },
      "source": [
        "### Import Data \n",
        "\n",
        "1. Commencez par installer tensorflow 2.0.0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWIWs0ujxxaB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "56dd9adc-abb0-480b-a42a-b80e4ebcadaa"
      },
      "source": [
        "# Installation TensorFlow\n",
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (49.6.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaavvJtfj6ra"
      },
      "source": [
        "2. Importez les librairies suivantes :\n",
        "\n",
        "* tensorflow \n",
        "* tensorflow_datasets\n",
        "* pandas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMBnbVdZygEr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d5feee6-c6ac-411d-efb4-3ae40edddf91"
      },
      "source": [
        "# Import des librairies TensorFlow & Pathlib \n",
        "import tensorflow as tf \n",
        "import tensorflow_datasets as tfds\n",
        "import pathlib \n",
        "import pandas as pd \n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIiJ3wIKkC_c"
      },
      "source": [
        "3. Copiez le lien ci-dessous et lisez le fichier qu'il contient avec `pandas`\n",
        "\n",
        "* https://go.aws/314bBDq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irik4DyW0acS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "dd2e96c3-109d-4bb7-da85-45ea987ca9f5"
      },
      "source": [
        "# Import du dataset dans Pandas \n",
        "dataset = pd.read_csv(\"https://go.aws/314bBDq\", error_bad_lines=False, encoding=\"utf-8\")\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>review</th>\n",
              "      <th>stars</th>\n",
              "      <th>date_format</th>\n",
              "      <th>time_of_day</th>\n",
              "      <th>hour_of_day</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>review_format</th>\n",
              "      <th>review_lang</th>\n",
              "      <th>month_year</th>\n",
              "      <th>review_len</th>\n",
              "      <th>review_nb_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>efb62a167fee5cf3678b24427de8e31f</td>\n",
              "      <td>Génial, fabuleux, exceptionnel ! J'aimerais qu...</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 18:17:00</td>\n",
              "      <td>18:17</td>\n",
              "      <td>18</td>\n",
              "      <td>Ven</td>\n",
              "      <td>génial  fabuleux  exceptionnel   j aimerais qu...</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>115</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e3be4f9c9e0b9572bfb2a5f88497bb14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-09-29 17:29:00</td>\n",
              "      <td>17:29</td>\n",
              "      <td>17</td>\n",
              "      <td>Ven</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1b8e5760162d867e9b9ca80f645bdc60</td>\n",
              "      <td>Toujours aussi magic, féerique !</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 16:46:00</td>\n",
              "      <td>16:46</td>\n",
              "      <td>16</td>\n",
              "      <td>Ven</td>\n",
              "      <td>toujours aussi magic  féerique</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fa330e5891a1bb486c3e9bf95c098726</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 15:52:00</td>\n",
              "      <td>15:52</td>\n",
              "      <td>15</td>\n",
              "      <td>Ven</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c1a693206aee1a2412d4bd9e45b80ec5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>2017-09-29 15:29:00</td>\n",
              "      <td>15:29</td>\n",
              "      <td>15</td>\n",
              "      <td>Ven</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            user_id  ... review_nb_words\n",
              "0  efb62a167fee5cf3678b24427de8e31f  ...              19\n",
              "1  e3be4f9c9e0b9572bfb2a5f88497bb14  ...               0\n",
              "2  1b8e5760162d867e9b9ca80f645bdc60  ...               4\n",
              "3  fa330e5891a1bb486c3e9bf95c098726  ...               0\n",
              "4  c1a693206aee1a2412d4bd9e45b80ec5  ...               0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_SUNZnzldIC"
      },
      "source": [
        "4. Nous allons avoir besoin des reviews en français. Filtrez donc les reviews pour qu'elles soient dans la bonne langue. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXLZFpg50swK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "324bb882-be8b-4a17-a7cc-a37249d8f344"
      },
      "source": [
        "# Prenons que les reviews françaises \n",
        "french_reviews = dataset[dataset.review_lang == \"french\"]\n",
        "french_reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>review</th>\n",
              "      <th>stars</th>\n",
              "      <th>date_format</th>\n",
              "      <th>time_of_day</th>\n",
              "      <th>hour_of_day</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>review_format</th>\n",
              "      <th>review_lang</th>\n",
              "      <th>month_year</th>\n",
              "      <th>review_len</th>\n",
              "      <th>review_nb_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>efb62a167fee5cf3678b24427de8e31f</td>\n",
              "      <td>Génial, fabuleux, exceptionnel ! J'aimerais qu...</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 18:17:00</td>\n",
              "      <td>18:17</td>\n",
              "      <td>18</td>\n",
              "      <td>Ven</td>\n",
              "      <td>génial  fabuleux  exceptionnel   j aimerais qu...</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>115</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1b8e5760162d867e9b9ca80f645bdc60</td>\n",
              "      <td>Toujours aussi magic, féerique !</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 16:46:00</td>\n",
              "      <td>16:46</td>\n",
              "      <td>16</td>\n",
              "      <td>Ven</td>\n",
              "      <td>toujours aussi magic  féerique</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>726b1a3e2664e8b075129bcd643dbf56</td>\n",
              "      <td>En vacances en région parisienne nous nous som...</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-09-29 00:37:00</td>\n",
              "      <td>00:37</td>\n",
              "      <td>0</td>\n",
              "      <td>Ven</td>\n",
              "      <td>en vacances en région parisienne nous nous som...</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>172</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>8a71763fbb3da7436b957681b24cc404</td>\n",
              "      <td>Tropbeaufinalpleinlesyeuxoreil</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 00:16:00</td>\n",
              "      <td>00:16</td>\n",
              "      <td>0</td>\n",
              "      <td>Ven</td>\n",
              "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ce7abd7798ee036d667c0ad84b85daa7</td>\n",
              "      <td>L'univers Disney reste merveilleux. Toutefois ...</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-09-28 20:24:00</td>\n",
              "      <td>20:24</td>\n",
              "      <td>20</td>\n",
              "      <td>Jeu</td>\n",
              "      <td>l univers disney reste merveilleux  toutefois ...</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>148</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             user_id  ... review_nb_words\n",
              "0   efb62a167fee5cf3678b24427de8e31f  ...              19\n",
              "2   1b8e5760162d867e9b9ca80f645bdc60  ...               4\n",
              "11  726b1a3e2664e8b075129bcd643dbf56  ...              25\n",
              "12  8a71763fbb3da7436b957681b24cc404  ...               1\n",
              "23  ce7abd7798ee036d667c0ad84b85daa7  ...              23\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As6OupSYl5La"
      },
      "source": [
        "5. Gardez uniquement les colonnes `review_format` & `stars`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe2j2atl1qNM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "813c1530-4dbe-4265-e601-9a9a85992bfa"
      },
      "source": [
        "# Prenons que les colonnes qui nous intéresse \n",
        "french_reviews = french_reviews[[\"review_format\", \"stars\"]]\n",
        "french_reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_format</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>génial  fabuleux  exceptionnel   j aimerais qu...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>toujours aussi magic  féerique</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>en vacances en région parisienne nous nous som...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>l univers disney reste merveilleux  toutefois ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        review_format  stars\n",
              "0   génial  fabuleux  exceptionnel   j aimerais qu...      5\n",
              "2                    toujours aussi magic  féerique        5\n",
              "11  en vacances en région parisienne nous nous som...      2\n",
              "12                     tropbeaufinalpleinlesyeuxoreil      5\n",
              "23  l univers disney reste merveilleux  toutefois ...      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7C2gLjZmK_s"
      },
      "source": [
        "6. Enlevez les valeurs manquantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2bB_tJlE1cf"
      },
      "source": [
        "# Suppression des NaN\n",
        "french_reviews = french_reviews.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j71sTc_qmQGw"
      },
      "source": [
        "7. Regardez les valeurs uniques pour chacune des étoiles "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSVWIW23vOp_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a4e8e71-992f-475c-9e9a-d10671d28c23"
      },
      "source": [
        "# Valeurs uniques\n",
        "french_reviews[\"stars\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 2, 4, 3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRV-YANSmVDo"
      },
      "source": [
        "8. Regardez la `shape` de votre base de données "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEI6wYJFKTxQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f12cc860-aa2b-4f8b-8624-6ab955635fd6"
      },
      "source": [
        "# Shape of french_reviews dataset\n",
        "french_reviews.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8474, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyzKbfEUmcVt"
      },
      "source": [
        "9. Créez un dataset tensorflow dans lequel vous insererez votre `reviews` et vos `stars`.\n",
        "\n",
        "NB : Votre variable cible & vos variables explicatives doivent être insérées dans un tuple. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A61O3Q7Z2v9G"
      },
      "source": [
        "# Création d'un tf dataset à partir de pandas \n",
        "tf_ds = tf.data.Dataset.from_tensor_slices((french_reviews[\"review_format\"].values, french_reviews[\"stars\"].values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjcoT4QxnZY6"
      },
      "source": [
        "10. Regardez un exemple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDHMPsoW2ZmE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "852a9804-473c-4a60-9869-552d676256a9"
      },
      "source": [
        "# Regardons un exemple \n",
        "for review, star in tf_ds.take(1):\n",
        "  print(review, star)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'g\\xc3\\xa9nial  fabuleux  exceptionnel   j aimerais que walt disney se r\\xc3\\xa9veille pour admirer ce qu il \\xc3\\xa0 laiss\\xc3\\xa9 derri\\xc3\\xa8re lui', shape=(), dtype=string) tf.Tensor(5, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ-aUk1mndZc"
      },
      "source": [
        "11. Randomisez votre dataset via `shuffle()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhBdUhtd5rC3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "88f4d48e-b94e-40c6-ae45-842e42fda0bd"
      },
      "source": [
        "# Shuffle le dataset \n",
        "tf_ds = tf_ds.shuffle(french_reviews.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-38934a51729d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Shuffle le dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: shuffle() missing 1 required positional argument: 'buffer_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8Duro5f8i7U"
      },
      "source": [
        "### Tokenize\n",
        "\n",
        "Nous allons maintenant passer par une phase de Tokenisation. Autrement dit, nous allons assigner un numéro à chacun des mots présent dans notre corpus de texte. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_awFJ9f3oahF"
      },
      "source": [
        "1. Créez un `Tokenizer` et mettez tous ces tokens dans un `set()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8scbZaESZ-q"
      },
      "source": [
        "# Création d'une instance Tokenizer\n",
        "tokenizer = tfds.features.text.Tokenizer()\n",
        "\n",
        "# Nous allons tokenizer chacun des mots en elevant les doublons via l'utilisation de set()\n",
        "vocabulary_set = set()\n",
        "for text_tensor, _ in tf_ds:\n",
        "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
        "  vocabulary_set.update(some_tokens)\n",
        "\n",
        "vocab_size = len(vocabulary_set)\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8XzTjXSpG9F"
      },
      "source": [
        "2. Instanciez un `TokenTextEncoder`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkwEN6hY-Dyv"
      },
      "source": [
        "# Création d'un nombre pour chacun des tokens que nous avons créés au dessus\n",
        "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR3cbKPYpPMS"
      },
      "source": [
        "3. Regardez un exemple "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJsKcBl5_T67"
      },
      "source": [
        "# Regardons le résultat sur un exemple \n",
        "for example, _ in tf_ds.take(1):\n",
        "  print(encoder.encode(example.numpy()))\n",
        "  print(example.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwYOdk4wpR2i"
      },
      "source": [
        "4. Appliquez votre encoder sur toutes les phrases de votre dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyMTkYfKDlNL"
      },
      "source": [
        "# Encodons maintenant tous les éléments d'un dataset\n",
        "def encode(text_tensor, label):\n",
        "  encoded_text = encoder.encode(text_tensor.numpy())\n",
        "  return encoded_text, label\n",
        "\n",
        "# Utilisation du fonction py_function pour encoder tout le dataset \n",
        "def encode_map_fn(text, label):\n",
        "  return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n",
        "\n",
        "all_encoded_data = tf_ds.map(encode_map_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ch6zwLZpW6i"
      },
      "source": [
        "5. Faites un `train_test_split` de vos données (gardez 70% environs dans le train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo7edz0PAr3v"
      },
      "source": [
        "# Train Test Split\n",
        "TAKE_SIZE = 6000\n",
        "\n",
        "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(50000)\n",
        "train_data = train_data.padded_batch(16,  padded_shapes=([-1], []))\n",
        "\n",
        "test_data = all_encoded_data.take(TAKE_SIZE)\n",
        "test_data = test_data.padded_batch(16, padded_shapes=([-1], []))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpUQB9xApckV"
      },
      "source": [
        "6. Regardez un batch de données "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8jxCfSSOUZ_"
      },
      "source": [
        " # Regardons un batch \n",
        "for review, star in train_data.take(1):\n",
        "  print(review)\n",
        "  print(star)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMaPEPk6QS4x"
      },
      "source": [
        "## Modeling \n",
        "\n",
        "Créons un modèle basé sur une couche LSTM pour classer nos différentes traductions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD3n6l1TplDN"
      },
      "source": [
        "1. Reprenez l'architecture que nous avons vu dans le tutoriel de NLP. Tentez simplement de la complexifier et éventuellement d'ajouter une couche CNN-1D qui peut aider le modèle à resumer l'information  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYxNpFYEUWI4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "1030c681-4a0c-4185-9940-69f715799f6a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                  # Couche d'Input Word Embedding    \n",
        "                  tf.keras.layers.Embedding(8000+1, 64),\n",
        "\n",
        "                  # Couche LSTM Bidirectionnelle\n",
        "                  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "\n",
        "                  # Couche CNN\n",
        "                  tf.keras.layers.Conv1D(16, 3, activation=\"relu\"),\n",
        "                  \n",
        "                  # Nouvelle couche LSTM\n",
        "                  tf.keras.layers.LSTM(32, return_sequences=False),               \n",
        "\n",
        "                  # Couche Dense classique \n",
        "                  tf.keras.layers.Dense(64, activation='relu'),\n",
        "                  tf.keras.layers.Dense(32, activation='relu'),\n",
        "                  tf.keras.layers.Dense(16, activation='relu'),\n",
        "                  tf.keras.layers.Dense(8, activation='relu'),\n",
        "\n",
        "                  # Couche de sortie avec le nombre de neurones en sortie égale au nombre de classe avec fonction softmax\n",
        "                  tf.keras.layers.Dense(6, activation=\"softmax\") # 6 neurones car les notes sontnumérotées de 1 à 5 et tf s'attends à ce que l'indice 0 existe\n",
        "                  # le modèle va prédire les notes de 0 à 5 et pas de 1 à 5\n",
        "                                              \n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 12)          96012     \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, None, 128)         39424     \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, None, 16)          6160      \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 32)                6272      \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 6)                 54        \n",
            "=================================================================\n",
            "Total params: 152,778\n",
            "Trainable params: 152,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3mFcvg5e7ka",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6243d6ae-dd97-4828-eb0d-11e0d3812af6"
      },
      "source": [
        "input_shape = (4, 10, 64)\n",
        "\n",
        "x = tf.random.normal(input_shape)\n",
        "print(x.shape)\n",
        "\n",
        "x_bidir = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
        "print(x_bidir.shape)\n",
        "\n",
        "y = tf.keras.layers.Conv1D(16, 3, activation='relu')(x_bidir)\n",
        "print(y.shape)\n",
        "\n",
        "128*16*3+16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 10, 64)\n",
            "(4, 10, 128)\n",
            "(4, 8, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-gKYS4_pu8I"
      },
      "source": [
        "2. Créez un `learning_rate_schedule` et compilez votre modèle avec la bonne fonction de coût "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOXk9F0YQ0j5"
      },
      "source": [
        "# Créons un learning rate schedule pour décroitre le learning rate à mesure que nous entrainons le modèle \n",
        "initial_learning_rate = 0.1\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "# Utilisation d'un compileur simple avec un optimiseur Adam pour le calcul de nos gradients \n",
        "optimizer= tf.keras.optimizers.Adam(\n",
        "    learning_rate = lr_schedule\n",
        ")\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5Rsbpckp3jK"
      },
      "source": [
        "3. Fittez votre modèle sur 40 epochs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qvWNK09RAPR"
      },
      "source": [
        "# Entrainement du modèle \n",
        "history = model.fit(train_data, epochs=40, validation_data=test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maI9cLyVp6k1"
      },
      "source": [
        "4. Notre modèle commence à avoir de bonnes performances. Mais, si vous regardez la répartition des classes de notre dataset. Nous avons un dataset très déséquilibré et centré autour des 5 étoiles. Créez donc un dictionnaire représentant les poids dans notre modèle pour chaque classe. Essayez de pénaliser les 5 étoiles et les 4 étoiles pour contrebalancer leur sur-présence "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fe2WfJEW08Z"
      },
      "source": [
        "# Balance des classes\n",
        "class_weight = {\n",
        "    0:0,\n",
        "    1:2,\n",
        "    2:2,\n",
        "    3:1,\n",
        "    4:0.75,\n",
        "    5:0.5\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7-NlOYnqSI-"
      },
      "source": [
        "5. Fittez à nouveau votre modèle sur 40 epochs en ajoutant le paramètre `class_weight= NAME_OF_YOUR_DICTIONNARY`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYM3h3gwXB0R"
      },
      "source": [
        "# Entrainement du modèle \n",
        "history = model.fit(train_data, \n",
        "                    epochs=40, \n",
        "                    validation_data=test_data,\n",
        "                    class_weight=class_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sVDED3Js3u9"
      },
      "source": [
        "6. Visualisez un exemple de prédiction sur vos données de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFf1gv90wfV0"
      },
      "source": [
        "for example, _ in test_data.take(1):\n",
        "  print(example, _)\n",
        "  print(model.predict_classes(example))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDnsfUFQTkyJ"
      },
      "source": [
        "## Evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Exbx9Bms-xZ"
      },
      "source": [
        "1. Créez un graphique visualisant votre loss par rapport au nombre d'epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mafVWHDFRIH6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualisation du processus d'entrainement sur la loss function \n",
        "plt.plot(history.history[\"loss\"], color=\"b\")\n",
        "plt.plot(history.history[\"val_loss\"], color=\"r\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzFU7VcMtF2j"
      },
      "source": [
        "2. Créez un graphique visualisant votre accuracy par rapport au nombre d'epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D96WZP8cVOFL"
      },
      "source": [
        "# Visualisation de l'entrainement sur l'accuracy \n",
        "plt.plot(history.history[\"sparse_categorical_accuracy\"], color=\"b\")\n",
        "plt.plot(history.history[\"val_sparse_categorical_accuracy\"], color=\"r\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0L-DGNguZsR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}